{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03176981-8e4e-4f7a-9212-e7de92731acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hoss\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import tempfile\n",
    "\n",
    "from hoss import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877dcd2-1bfa-49b2-9bbd-6f08ea14cf89",
   "metadata": {},
   "source": [
    "## Connect to local server\n",
    "This notebook demonstrates basic operations using a single Hoss server.\n",
    "For these demo notebooks, it's assumed you have the `admin` role and are running the server locally\n",
    "on localhost. If using a different server, be sure to change the endpoint in the `.connect()` call.\n",
    "\n",
    "We start by connecting the the \"local\" server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42957e48-f1c5-4511-8dd9-a5f7b02e78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_local = hoss.connect('http://localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5450b39-bf83-4bd9-ac19-f2b85c5010fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Existing Namespaces:\")\n",
    "print(server_local.list_namespaces())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730df799-88a8-4ea3-9fd3-09b19f6387e1",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "First load the default namespace and then create a dataset inside the namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978bae0-533f-4c56-a3f7-e4ea56024545",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = server_local.get_namespace('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5aad2e-80a2-480b-b7a5-a7a32857270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ns.create_dataset(\"hash-test\", \"A dataset for demoing how to check hashes\")\n",
    "ds.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc064fb-8633-4bb1-b89c-b99a02d30d4f",
   "metadata": {},
   "source": [
    "## Write a file from disk and check its hash manually\n",
    "\n",
    "We can access the hash value that is computed by the object store via the `etag` attribute of a dataset object reference.\n",
    "\n",
    "If a file is written with a single part (be default <= 8MB), then computing the etag is straight forward. Simply compute\n",
    "the hexdigest of the md5 hash of the file.\n",
    "\n",
    "Note, the ETag will always be wrapped in `\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae64cb3-a2fc-4e81-be61-3e3b4a167314",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"example-file.txt\")\n",
    "\n",
    "f1 = ds / \"example-file.txt\"\n",
    "f1.write_from(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb2009-3d25-4261-a6bb-ac007008b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the etag value of the ref\n",
    "f1.etag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d342ee-a919-475c-b396-d2cc423e9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_hash = hashlib.md5(open(filename,'rb').read()).hexdigest()\n",
    "print(computed_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad839e-8777-49cc-8180-168fcb389a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if f1.etag == f'\"{computed_hash}\"':\n",
    "    print(\"hashes match!\")\n",
    "else:\n",
    "    print(\"hashes do NOT match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94a219-43c2-4d43-80b3-ccc8fd53058b",
   "metadata": {},
   "source": [
    "## Verify hashes using hoss-client utility function\n",
    "\n",
    "If a file is larger than the multipart threshold, computing the etag is more complex. The etag becomes\n",
    "the md5 hexdigest of all part md5 digests concatenated, with `-<num parts>` appended.\n",
    "\n",
    "To simplify checking if a local file matches that in the remote object store, utility functions are provided to\n",
    "compute etag values and also to check if a DatasetRef instance matches the contents of a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba936827-b433-4241-a1ab-3843b1d392a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a small file\n",
    "with tempfile.NamedTemporaryFile(mode='wt', delete=False) as tf:\n",
    "    tf.write(\"this is a small file\")\n",
    "    tf.flush()\n",
    "\n",
    "    obj = ds / \"small-file.dat\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d337c2-55d8-4740-afcb-0acb5b0bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file hash function works as expected on a small file\n",
    "local_hash = utilities.hash_file(tf.name)\n",
    "print(local_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f4e7a-3031-49da-9912-abcd14bb5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file to the object store\n",
    "obj.write_from(tf.name)\n",
    "\n",
    "# Verify hash matches\n",
    "assert utilities.etag_does_match(obj, tf.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e7a7e-b995-4f53-a019-df24a6783818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the temp file\n",
    "os.remove(tf.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39e168-a46d-4632-985a-74176e36ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a file that is about 20MB, which will trigger multipart uploads\n",
    "with tempfile.NamedTemporaryFile(mode='wt', delete=False) as tf:\n",
    "    tf.write(\"1234567890\" * 1024 * 2000)\n",
    "    tf.flush()\n",
    "\n",
    "    obj = ds / \"large-file.dat\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0cfec-5917-4461-8691-f4cee43045e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file hash function works as expected on a small file\n",
    "local_hash = utilities.hash_file(tf.name)\n",
    "print(local_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872ca52-4789-462c-96e8-1912619d97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file to the object store\n",
    "obj.write_from(tf.name)\n",
    "\n",
    "# Verify hash matches\n",
    "assert utilities.etag_does_match(obj, tf.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a41bb-d43e-4baf-ad89-3d61c2da8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the temp file\n",
    "os.remove(tf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f57542-c3e5-4fd3-940d-a7dca9c6ec59",
   "metadata": {},
   "source": [
    "## Clean up this example\n",
    "\n",
    "Run these cells to remove the resources created during the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe09148-28bb-4b3f-8e22-83f0c489ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.delete_dataset(\"hash-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2283d88-2293-4c18-8b52-3bc6be014f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
